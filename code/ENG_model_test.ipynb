{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339baa35-a0e9-4d65-bb30-81ba8e93120a",
   "metadata": {},
   "source": [
    "<h3>Ingliskeelsete RoBERTa mudelite testimine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649a5104-89ff-40d0-931a-f711123595e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c860059a-3fda-4ea3-bf4d-19193ecc455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taunotam\\Anaconda3\\envs\\ETP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bc907d-bd84-416a-9914-358a1e2f81e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taunotam\\AppData\\Local\\Temp\\ipykernel_19176\\3503521418.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'POSITIVE' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[\"category\"] == 1, \"category\"] = \"POSITIVE\"\n"
     ]
    }
   ],
   "source": [
    "df.loc[df[\"category\"] == 1, \"category\"] = \"POSITIVE\"\n",
    "df.loc[df[\"category\"] == 0, \"category\"] = \"NEUTRAL\"\n",
    "df.loc[df[\"category\"] == -1, \"category\"] = \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b89b01-8fc0-4691-ae97-d638a73a14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['clean_comment'])\n",
    "df = df[df['clean_comment'].apply(len) <= 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fc930f-f3bc-488a-a7de-5a7f4f13cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you should all sit down together and watch the...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jesus was zen meets jew</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37244</th>\n",
       "      <td>jesus</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37245</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37246</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37247</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37248</th>\n",
       "      <td>facebook itself now working bjp’ cell</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "0       family mormon have never tried explain them t...  POSITIVE\n",
       "2      seriously don say thing first all they won get...  NEGATIVE\n",
       "3      what you have learned yours and only yours wha...   NEUTRAL\n",
       "5      you should all sit down together and watch the...  NEGATIVE\n",
       "7                               jesus was zen meets jew    NEUTRAL\n",
       "...                                                  ...       ...\n",
       "37244                                              jesus   NEUTRAL\n",
       "37245  kya bhai pure saal chutiya banaya modi aur jab...  POSITIVE\n",
       "37246              downvote karna tha par upvote hogaya    NEUTRAL\n",
       "37247                                         haha nice   POSITIVE\n",
       "37248             facebook itself now working bjp’ cell    NEUTRAL\n",
       "\n",
       "[34536 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07821420-b6b5-4599-a959-8e683157c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df['clean_comment'])[:1000]\n",
    "label = list(df['category'])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5073c5-b878-4405-aaff-561d0897afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06cd2fba-91d1-43ae-8394-56efb530431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|███████████████████████████████████████████████████████████| 3.78M/3.78M [00:02<00:00, 1.82MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████| 901k/901k [00:00<00:00, 3.15MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████| 167k/167k [00:00<00:00, 757kB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████| 45615/45615 [00:00<00:00, 561935.13 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████| 12284/12284 [00:00<00:00, 614171.30 examples/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████| 2000/2000 [00:00<00:00, 333251.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tweet_eval', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90b853dc-3cf0-4ede-85a5-6cdb7255d60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12284\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd31e1f9-7ff1-433c-bec4-84b9200d7dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 45615\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]#[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e83f2b3-09e4-4b74-8e4f-000f12cbaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"siebert/sentiment-roberta-large-english\"\n",
    "specific_model = pipeline(\"sentiment-analysis\",model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb871acf-21eb-4c78-a3ee-f189fc6ca716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dffcc000-5105-4c4a-ad7c-7e96bfdf7187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [15:39<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4565000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"][\"label\"][:2000]))):\n",
    "    predictions.append(specific_model(dataset[\"test\"][\"text\"][i])[0][\"label\"])\n",
    "    label = dataset[\"test\"][\"label\"][i]\n",
    "\n",
    "    if label == 2:\n",
    "        labels.append(\"POSITIVE\")\n",
    "    elif label == 1:\n",
    "        labels.append(\"NEUTRAL\")\n",
    "    elif label == 0:\n",
    "        labels.append(\"NEGATIVE\")\n",
    "\n",
    "print(\"F1 Score:\", f1_score(labels, predictions, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40ed95f8-0d1c-4347-9a6d-bdb8ad3e5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "specific_model = pipeline(\"sentiment-analysis\",model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "194ad135-a324-474a-89fe-6e2c4abd81cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [05:33<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7190000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"][\"label\"][:2000]))):\n",
    "    predictions.append(specific_model(dataset[\"test\"][\"text\"][i])[0][\"label\"])\n",
    "    label = dataset[\"test\"][\"label\"][i]\n",
    "    if label == 2:\n",
    "        labels.append(\"LABEL_2\")\n",
    "    elif label == 1:\n",
    "        labels.append(\"LABEL_1\")\n",
    "    elif label == 0:\n",
    "        labels.append(\"LABEL_0\")\n",
    "\n",
    "\n",
    "print(\"F1 Score:\", f1_score(labels, predictions, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a46cdfdb-0378-4e2b-9f17-f6228e0ace48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "specific_model = pipeline(\"sentiment-analysis\", model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc99f697-1019-4e65-96a2-e8e866e17b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [05:41<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"][\"label\"][:2000]))):\n",
    "    predictions.append(specific_model(dataset[\"test\"][\"text\"][i])[0][\"label\"])\n",
    "    label = dataset[\"test\"][\"label\"][i]\n",
    "    if label == 2:\n",
    "        labels.append(\"positive\")\n",
    "    elif label == 1:\n",
    "        labels.append(\"neutral\")\n",
    "    elif label == 0:\n",
    "        labels.append(\"negative\")\n",
    "\n",
    "print(\"F1 Score:\", f1_score(labels, predictions, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8f4d7-825a-4b1a-8ed7-3289c1975cf2",
   "metadata": {},
   "source": [
    "<h3>Proovime teise datasetiga hinnata täpsust</h3>\n",
    "<h5>Tegmist pole inim-annoteeritud andmestikuga, mistõttu nende tulemuste põhjal mudelit ei vali, kuid huvipärast vaatame tulemusi.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d62044b-55bc-4f89-afc9-dd59f8db1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reddit_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8255a92-4221-4ec3-9272-142293e42d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>once again trump fails see the big picture edu...</td>\n",
       "      <td>1</td>\n",
       "      <td>26561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what model did you follow attract youth from r...</td>\n",
       "      <td>1</td>\n",
       "      <td>1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who the this guy the bottom</td>\n",
       "      <td>1</td>\n",
       "      <td>33890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>still can believe that the hasn addressed the...</td>\n",
       "      <td>2</td>\n",
       "      <td>28759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apanasana sort top all course think have past...</td>\n",
       "      <td>1</td>\n",
       "      <td>15710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>going allahabad day after would anyone like v...</td>\n",
       "      <td>1</td>\n",
       "      <td>24726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>results will out today but government formatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>25724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>from congress mukt bharat ready reach out the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>25666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>ora che penso pisciato mit boston</td>\n",
       "      <td>1</td>\n",
       "      <td>22435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>this reminds kunkka old dota loading screen ar...</td>\n",
       "      <td>2</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7430 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     once again trump fails see the big picture edu...      1   \n",
       "1     what model did you follow attract youth from r...      1   \n",
       "2                          who the this guy the bottom       1   \n",
       "3      still can believe that the hasn addressed the...      2   \n",
       "4      apanasana sort top all course think have past...      1   \n",
       "...                                                 ...    ...   \n",
       "7425   going allahabad day after would anyone like v...      1   \n",
       "7426  results will out today but government formatio...      0   \n",
       "7427  from congress mukt bharat ready reach out the ...      2   \n",
       "7428                 ora che penso pisciato mit boston       1   \n",
       "7429  this reminds kunkka old dota loading screen ar...      2   \n",
       "\n",
       "      __index_level_0__  \n",
       "0                 26561  \n",
       "1                  1801  \n",
       "2                 33890  \n",
       "3                 28759  \n",
       "4                 15710  \n",
       "...                 ...  \n",
       "7425              24726  \n",
       "7426              25724  \n",
       "7427              25666  \n",
       "7428              22435  \n",
       "7429                423  \n",
       "\n",
       "[7430 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42e761cc-6a54-46b4-a634-71c6d5aced1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])\n",
    "df = df[df['text'].apply(len) <= 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdd8b31c-e8fa-4179-a553-41354a1d7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df['text'])[:1000]\n",
    "label = list(df['label'])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbce39ff-5b8d-484a-b8e7-40dbf3ec157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"siebert/sentiment-roberta-large-english\"\n",
    "specific_model = pipeline(\"sentiment-analysis\",model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "004a177a-0f1b-4d2e-a4c8-faffb7ee4cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Täpsus: 0.374\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(text)):\n",
    "    if specific_model(text[i])[0][\"label\"] == \"POSITIVE\" and label[i] == 2:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"NEUTRAL\" and label[i] == 1:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"NEGATIVE\" and label[i] == 0:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(\"Täpsus:\", results.count(1)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2cf9386-2b5b-4cf9-98f1-96e6eccfd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "specific_model = pipeline(\"sentiment-analysis\",model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc92da05-e437-48b2-a8de-1c589796704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Täpsus: 0.56\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(text)):\n",
    "    if specific_model(text[i])[0][\"label\"] == \"LABEL_2\" and label[i] == 2:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"LABEL_1\" and label[i] == 1:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"LABEL_0\" and label[i] == 0:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(\"Täpsus:\", results.count(1)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4948c50-9048-4acf-94c6-24258cb4a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "specific_model = pipeline(\"sentiment-analysis\", model=model_path ,tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "828fec8b-ba74-44a7-ab70-58610aa5bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Täpsus: 0.571\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(text)):\n",
    "    if specific_model(text[i])[0][\"label\"] == \"positive\" and label[i] == 2:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"neutral\" and label[i] == 1:\n",
    "        results.append(1)\n",
    "    elif specific_model(text[i])[0][\"label\"] == \"negative\" and label[i] == 0:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(\"Täpsus:\", results.count(1)/len(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
